# BasisPilot 题目标签体系 (Taxonomy v1) — 架构与使用文档

> 版本: v1.0
> 更新日期: 2026-02-21
> 前置条件: 真题库系统已初始化, 430+ 题目已入库

---

## 1. 系统概述

题目标签体系为 430 道 MAP 题库提供**多维度、版本化、AI 可批量打标**的标签能力，从 Bloom 认知层级到 CCSS 对标到易错点诊断，全面提升测评系统的诊断深度。

```
┌───────────────────────────────────────────────────────────────┐
│                    题目标签体系架构                              │
│                                                               │
│  定义层 (YAML)          引擎层 (Python)          消费层         │
│  ──────────            ──────────              ──────         │
│                                                               │
│  taxonomy_v1.yaml ──┐                                         │
│  ccss_math.yaml  ──┼──▶ loader.py ──▶ TaxonomyBundle         │
│  ccss_ela.yaml   ──┤       │              │                   │
│  misconceptions  ──┘       ▼              ▼                   │
│                     models.py      prompts.py                 │
│                         │              │                      │
│                         ▼              ▼                      │
│                     tagger.py ◀── LLM (gpt-4o-mini)          │
│                         │                                     │
│                         ▼                                     │
│                     db.py ──────▶ assessment_questions         │
│                         │          (tags[] + metadata.taxonomy)│
│                         ▼                                     │
│                   analytics.py ──▶ 覆盖率报告                   │
│                                                               │
│  CLI 入口:                                                    │
│    taxonomy --validate    校验 YAML 定义                       │
│    tag --dry-run          AI 试标注预览                         │
│    tag                    全量打标 (写入 DB)                    │
│    tag-stats              分布统计报告                          │
│                                                               │
│  消费方:                                                      │
│    assessment_engine.py   Bloom's 分布 + 技能掌握度 + 易错点   │
│    CAT 自适应出题          标签驱动的精准推题 (未来)              │
│    学生诊断报告            多维认知画像 (未来)                    │
└───────────────────────────────────────────────────────────────┘
```

---

## 2. 标签维度总览

| 维度 | 前缀 | 取值示例 | 来源 |
|------|------|---------|------|
| Bloom's 认知层级 | `bloom:` | `bloom:apply` | LLM 打标 |
| Webb's DOK | `dok:` | `dok:2` | LLM 打标 |
| 难度分段 | `band:` | `band:proficient` | 规则计算 (difficulty → band) |
| CCSS 标准码 | `ccss:` | `ccss:7.RP.A.2` | LLM 打标 |
| 认知技能 | `skill:` | `skill:quantitative_reasoning.proportional_thinking` | LLM + 规则 |
| 情境类型 | `context:` | `context:contextual` | LLM + 规则 |
| 考试对标 | `test:` | `test:map_growth` | 规则 |
| 时间复杂度 | `time:` | `time:standard` | LLM 打标 |
| 语言复杂度 | `lang:` | `lang:intermediate` | LLM 打标 (ELA) |
| 易错点 | `mc:` | `mc:MC-MATH-FRAC-001` | LLM 打标 |

---

## 3. 存储约定 (零 Schema 迁移)

利用已有的 `tags TEXT[]` 和 `metadata JSONB` 列，无需数据库迁移。

### 3.1 `tags[]` — 前缀命名空间 (快速查询)

```sql
-- 示例: 一道 G7 比例推理题的 tags 数组
tags = ARRAY[
  'bloom:apply', 'dok:2', 'band:proficient',
  'ccss:7.RP.A.2', 'skill:quantitative_reasoning.proportional_thinking',
  'context:contextual', 'test:map_growth', 'time:standard',
  'mc:MC-MATH-FRAC-001',
  'ratio_proportion', 'map_style'   -- 保留遗留标签
]
```

查询示例:
```sql
-- 查找所有 Bloom's apply 层级的题目
SELECT * FROM assessment_questions WHERE 'bloom:apply' = ANY(tags);

-- 查找对标 CCSS 7.RP 的题目
SELECT * FROM assessment_questions WHERE EXISTS (
  SELECT 1 FROM unnest(tags) t WHERE t LIKE 'ccss:7.RP%'
);

-- 统计 Bloom's 分布
SELECT t AS bloom_level, COUNT(*) FROM assessment_questions, unnest(tags) t
WHERE t LIKE 'bloom:%' GROUP BY t ORDER BY COUNT(*) DESC;
```

### 3.2 `metadata.taxonomy` — 丰富结构化数据

```json
{
  "taxonomy": {
    "version": "1.0",
    "tagged_at": "2026-02-21T14:30:00Z",
    "blooms": {"level": "apply", "rationale": "Requires applying unit rate concept to multi-step context"},
    "dok": {"level": 2, "rationale": "Skill/concept application with one step of reasoning"},
    "rit_estimate": 208,
    "ccss_codes": ["7.RP.A.2"],
    "cognitive_skills": {
      "primary": "quantitative_reasoning.proportional_thinking",
      "secondary": ["quantitative_reasoning.number_sense"]
    },
    "misconceptions": {
      "detectable": ["MC-MATH-FRAC-001"],
      "if_wrong_answer": {"A": "MC-MATH-RATIO-002"}
    },
    "learning_objective": "Apply unit rates to solve multi-step problems",
    "time_estimate_sec": 75,
    "context_type": "contextual",
    "test_alignment": ["map_growth", "sat"],
    "language_complexity": null
  }
}
```

**幂等保证**: 打标器检查 `metadata.taxonomy.version == "1.0"` 跳过已标注题目。

---

## 4. 文件结构

### 4.1 数据定义层

```
data/taxonomy/
├── taxonomy_v1.yaml         # 主定义: Bloom's/DOK/band/技能树/前缀注册表
├── ccss_math.yaml           # 139 条 Common Core 数学标准 (G5-G12)
├── ccss_ela.yaml            # 84 条 Common Core 英语标准 (G5-G12)
└── misconceptions.yaml      # 41 条易错点 (26 数学 + 15 英语)
```

### 4.2 Python 包

```
src/basis_expert_council/taxonomy/
├── __init__.py              # 包导出: QuestionTaxonomyTags, load_taxonomy, QuestionTagger 等
├── models.py                # Pydantic 模型: QuestionTaxonomyTags, TaxonomyBundle, CCSStandard, Misconception
├── loader.py                # YAML 加载/缓存/校验: load_taxonomy(), validate_taxonomy()
├── prompts.py               # LLM 系统提示 + 用户提示模板 + 上下文构建
├── tagger.py                # QuestionTagger 类: LLM 批量打标引擎
└── analytics.py             # 标签分布统计 + 覆盖率分析
```

### 4.3 已修改文件

| 文件 | 变更 |
|------|------|
| `db.py` | +3 函数: `get_questions_for_tagging()`, `update_question_tags()`, `get_tag_stats()`; `get_session_answers()` 加入 `q.tags` |
| `question_bank/cli.py` | +3 子命令: `taxonomy`, `tag`, `tag-stats` |
| `question_bank/map_transformer.py` | `get_tags()` 升级为带前缀标签 |
| `assessment_engine.py` | `compute_session_stats()` 增加 Bloom's 分布 + 技能掌握度 + 易错点检测 |
| `pyproject.toml` | +`pydantic`, `PyYAML`, `openai` 依赖 |

---

## 5. Bloom's Taxonomy 六级定义

| 层级 | 标签 | 含义 | 典型题目动词 |
|------|------|------|------------|
| 1 | `bloom:remember` | 回忆事实和基本概念 | 定义、列举、识别 |
| 2 | `bloom:understand` | 解释想法或概念 | 解释、分类、概括 |
| 3 | `bloom:apply` | 在新情境中使用信息 | 计算、解决、应用 |
| 4 | `bloom:analyze` | 建立联系、分解组织 | 比较、推断、区分 |
| 5 | `bloom:evaluate` | 论证立场或做出判断 | 评估、论证、批判 |
| 6 | `bloom:create` | 产生新的或原创的作品 | 设计、构建、开发 |

---

## 6. Webb's DOK 四级定义

| 级别 | 标签 | 含义 | 示例 |
|------|------|------|------|
| 1 | `dok:1` | 回忆 — 事实性知识提取 | "What is 7 × 8?" |
| 2 | `dok:2` | 技能/概念 — 需要推理的一步操作 | "Solve for x: 3x + 5 = 20" |
| 3 | `dok:3` | 策略性思维 — 多步骤、需计划 | "Design an experiment to test..." |
| 4 | `dok:4` | 扩展性思维 — 综合多来源、长期项目 | "Write a research paper analyzing..." |

---

## 7. 难度分段与 RIT 对照

| 分段 | 标签 | difficulty 范围 | RIT 参考 |
|------|------|----------------|----------|
| Foundational | `band:foundational` | 0.00 – 0.25 | 160 – 190 |
| Basic | `band:basic` | 0.25 – 0.45 | 190 – 210 |
| Proficient | `band:proficient` | 0.45 – 0.65 | 210 – 230 |
| Advanced | `band:advanced` | 0.65 – 0.85 | 230 – 250 |
| Elite | `band:elite` | 0.85 – 1.00 | 250 – 270 |

---

## 8. 认知技能树

```
quantitative_reasoning/
├── number_sense                 # 数感
├── proportional_thinking        # 比例推理
├── algebraic_thinking           # 代数思维
├── data_analysis                # 数据分析
├── spatial_reasoning            # 空间推理
└── statistical_reasoning        # 统计推理

reading_comprehension/
├── literal_comprehension        # 字面理解
├── inferential_comprehension    # 推断理解
├── evaluative_comprehension     # 评价性理解
├── vocabulary_knowledge         # 词汇知识
└── text_structure_analysis      # 文本结构分析

language_mechanics/
├── grammar_usage                # 语法运用
├── sentence_construction        # 句子构造
├── punctuation_mechanics        # 标点机制
└── writing_conventions          # 写作规范

scientific_reasoning/
├── observation                  # 观察
├── hypothesis_formation         # 假设形成
├── experimental_design          # 实验设计
├── data_interpretation          # 数据解读
└── model_building               # 模型构建

historical_thinking/
├── chronological_reasoning      # 时序推理
├── causation_analysis           # 因果分析
├── sourcing                     # 史料辨析
├── contextualization            # 历史语境化
└── argumentation                # 论证
```

---

## 9. CLI 使用指南

所有命令通过 `python -m basis_expert_council.question_bank` 调用:

### 9.1 查看标签体系

```bash
# 查看标签体系概要
python -m basis_expert_council.question_bank taxonomy

# 输出示例:
# 标签体系 v1.0
#   Bloom's 层级: 6 级
#   DOK 层级: 4 级
#   难度分段: 5 段
#   认知技能: 5 大类, 26 子项
#   CCSS 数学标准: 139 条
#   CCSS 英语标准: 84 条
#   易错点目录: 41 条
```

### 9.2 校验 YAML 定义

```bash
python -m basis_expert_council.question_bank taxonomy --validate

# 成功: "标签体系校验通过!"
# 失败: 列出所有加载错误
```

### 9.3 AI 批量打标

```bash
# 试运行: 预览 5 道题的标签 (不写入 DB)
python -m basis_expert_council.question_bank tag --dry-run --limit 5

# 按学科打标
python -m basis_expert_council.question_bank tag --subject math --limit 50

# 全量打标 (430 题, ~86 次 LLM 调用)
python -m basis_expert_council.question_bank tag

# 自定义批大小
python -m basis_expert_council.question_bank tag --batch-size 10
```

**环境变量:**
| 变量 | 默认值 | 说明 |
|------|--------|------|
| `TAXONOMY_LLM_MODEL` | (fallback MEM0_LLM_MODEL → gpt-4o-mini) | 打标使用的 LLM 模型 |
| `OPENAI_API_KEY` | — | OpenAI API 密钥 |
| `OPENAI_BASE_URL` | https://api.openai.com/v1 | API 端点 (兼容第三方) |

### 9.4 标签分布统计

```bash
python -m basis_expert_council.question_bank tag-stats

# 输出示例:
# === 题目标签分布统计 ===
# 总计: 430 题 | 已标注: 430 (100.0%) | 未标注: 0
#
# Bloom's 分布:
#   apply        : 180 (41.9%)
#   understand   : 120 (27.9%)
#   analyze      :  65 (15.1%)
#   remember     :  40 ( 9.3%)
#   evaluate     :  20 ( 4.7%)
#   create       :   5 ( 1.2%)
# ...
```

---

## 10. 诊断报告增强

`assessment_engine.py` 的 `compute_session_stats()` 现在返回三个新字段:

### 10.1 `blooms_distribution`

```json
{
  "apply": {"total": 8, "correct": 6, "mastery": 0.75},
  "understand": {"total": 5, "correct": 4, "mastery": 0.80},
  "analyze": {"total": 3, "correct": 1, "mastery": 0.33}
}
```

用途: 雷达图展示学生在不同认知层级的掌握度。

### 10.2 `skill_mastery`

```json
{
  "quantitative_reasoning.proportional_thinking": {"total": 4, "correct": 3, "mastery": 0.75},
  "quantitative_reasoning.algebraic_thinking": {"total": 3, "correct": 1, "mastery": 0.33}
}
```

用途: 精准定位薄弱认知技能，驱动个性化学习路径。

### 10.3 `detected_misconceptions`

```json
["MC-MATH-FRAC-001", "MC-MATH-RATIO-002"]
```

用途: 结合 `misconceptions.yaml` 中的纠正建议，生成针对性的错题分析。

---

## 11. 数据流转图

```
                     ┌─────────────────┐
                     │  taxonomy_v1.yaml │
                     │  ccss_math.yaml   │
                     │  ccss_ela.yaml    │
                     │  misconceptions   │
                     └────────┬─────────┘
                              │ load_taxonomy()
                              ▼
                     ┌─────────────────┐
                     │ TaxonomyBundle  │
                     │  .definition     │
                     │  .ccss_math      │
                     │  .ccss_ela       │
                     │  .misconceptions │
                     └────────┬─────────┘
                              │
              ┌───────────────┼───────────────┐
              │               │               │
              ▼               ▼               ▼
     build_taxonomy     QuestionTagger   validate_taxonomy()
     _context()         .tag_batch()         │
              │               │               ▼
              ▼               │          CLI: taxonomy
     LLM Prompt ──────▶ LLM Call             --validate
                              │
                              ▼
                  QuestionTaxonomyTags
                     .to_tags() ──────▶ tags TEXT[]
                     .model_dump() ───▶ metadata.taxonomy JSONB
                              │
                              ▼
                    assessment_questions
                              │
              ┌───────────────┼───────────────┐
              │               │               │
              ▼               ▼               ▼
         tag-stats    assessment_engine   CAT 出题
         (analytics)  (bloom's分布/       (标签驱动
                       技能掌握度/          精准推题)
                       易错点检测)
```

---

## 12. 扩展指南

### 12.1 新增标签维度

1. 在 `taxonomy_v1.yaml` 中添加定义
2. 在 `tag_prefixes` 中注册新前缀
3. 在 `models.py` 的 `QuestionTaxonomyTags` 中添加字段
4. 更新 `to_tags()` 方法生成新前缀标签
5. 更新 `prompts.py` 的 SYSTEM_PROMPT 指导 LLM 填写新字段
6. 运行 `tag --dry-run --limit 5` 验证

### 12.2 升级标签版本

1. 创建 `taxonomy_v2.yaml` (保留 v1)
2. 在 models.py 中更新 `version = "2.0"`
3. 打标器将自动跳过 v1 题目，只处理未达 v2 的题目
4. 或修改 `skip_tagged` 逻辑强制重打

### 12.3 新增学科易错点

在 `misconceptions.yaml` 中添加条目:

```yaml
- id: "MC-PHYS-FORCE-001"
  subject: "physics"
  topic: "forces"
  description_en: "Confusing mass with weight"
  description_zh: "混淆质量与重量"
  example: "A 10 kg object weighs 10 N (should be ~98 N)"
  correction_en: "Weight = mass × gravitational acceleration (W = mg)"
  correction_zh: "重量 = 质量 × 重力加速度 (W = mg)"
  grades: ["G6", "G7", "G8"]
  severity: "critical"
```

### 12.4 新增 CCSS 标准

在 `ccss_math.yaml` 或 `ccss_ela.yaml` 中添加:

```yaml
"HSA.APR.B.3":
  domain: "Algebra"
  cluster: "Understand the relationship between zeros and factors of polynomials"
  standard: "Identify zeros of polynomials and use them to construct a rough graph"
  grade: 10
```

---

## 13. 常见问题

**Q: 打标需要多长时间？**
A: 430 题 / 5 题每批 = 86 次 LLM 调用。使用 gpt-4o-mini 约需 10-15 分钟。

**Q: 打标失败怎么办？**
A: 打标器幂等设计 — 重新运行 `tag` 命令会自动跳过已打标题目，只处理失败的题目。

**Q: 如何验证打标质量？**
A: 运行 `tag-stats` 查看分布；随机抽检 20 题确认 Bloom's/DOK 准确率 >85%。

**Q: 遗留标签会丢失吗？**
A: 不会。LLM 打标后 `to_tags()` 生成的新标签会替换 `tags[]`，但 `map_transformer.py` 升级后已在初次导入时包含遗留 + 前缀标签。对已入库数据，LLM 打标时 tagger 会生成完整的带前缀标签列表。
